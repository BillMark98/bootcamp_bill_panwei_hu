{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e4df9a",
   "metadata": {},
   "source": [
    "# Stage 15 — Orchestration & System Design (Filled)\n",
    "\n",
    "This notebook is **self-contained** and satisfies the Stage 15 homework deliverables without creating any extra files.\n",
    "It includes:\n",
    "- Pipeline tasks & boundaries (4–8 tasks)\n",
    "- Dependencies (DAG) rendered **inline** with `matplotlib`\n",
    "- Reliability patterns: logging, checkpoints, idempotency (in-memory demo)\n",
    "- Failure points & retry policy (with exponential backoff utility)\n",
    "- What to automate now vs manual gate (with rationale)\n",
    "- Minimal runbook snippets\n",
    "- Final deliverables checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1232f",
   "metadata": {},
   "source": [
    "## A. Pipeline Tasks & Boundaries\n",
    "\n",
    "1. **Ingest Raw Data**  \n",
    "   **Input:** `data/raw/` (dated partitions)  \n",
    "   **Output:** `data/ingested/data_ingested.parquet`  \n",
    "   **Idempotent:** Yes (immutable inputs → deterministic output)  \n",
    "   **Logging:** `logs/ingest.log` (pattern)  \n",
    "   **Checkpoint:** `checkpoints/ingest.ok` (pattern)\n",
    "\n",
    "2. **Validate & Profile**  \n",
    "   **Input:** `data/ingested/data_ingested.parquet`  \n",
    "   **Output:** `reports/data_profile.json`, `reports/validation_summary.md`  \n",
    "   **Idempotent:** Yes  \n",
    "   **Logging:** `logs/validate.log`  \n",
    "   **Checkpoint:** `checkpoints/validate.ok`\n",
    "\n",
    "3. **Clean & Feature Build**  \n",
    "   **Input:** ingested data + `config/schema.yaml`  \n",
    "   **Output:** `data/processed/features.parquet`  \n",
    "   **Idempotent:** Yes (deterministic transforms; seed fixed)  \n",
    "   **Logging:** `logs/clean.log`  \n",
    "   **Checkpoint:** `checkpoints/clean.ok`\n",
    "\n",
    "4. **Train Model**  \n",
    "   **Input:** `data/processed/features.parquet`, `config/train.yaml`  \n",
    "   **Output:** `models/model.pkl`, `reports/train_metrics.json`  \n",
    "   **Idempotent:** Yes if inputs/params unchanged (content hashes)  \n",
    "   **Logging:** `logs/train.log`  \n",
    "   **Checkpoint:** `checkpoints/train.ok`\n",
    "\n",
    "5. **Evaluate & Drift Checks**  \n",
    "   **Input:** `models/model.pkl`, held-out data  \n",
    "   **Output:** `reports/eval_metrics.json`, `reports/drift_report.md`  \n",
    "   **Idempotent:** Yes  \n",
    "   **Logging:** `logs/eval.log`  \n",
    "   **Checkpoint:** `checkpoints/eval.ok`\n",
    "\n",
    "6. **Package for Serving**  \n",
    "   **Input:** `models/model.pkl`  \n",
    "   **Output:** `artifact/model_v{hash}/manifest.json` (hash = data+params)  \n",
    "   **Idempotent:** Yes  \n",
    "   **Logging:** `logs/package.log`  \n",
    "   **Checkpoint:** `checkpoints/package.ok`\n",
    "\n",
    "7. **Report / Deliver**  \n",
    "   **Input:** metrics + templates  \n",
    "   **Output:** `deliverables/report.md` (+ images)  \n",
    "   **Idempotent:** Yes  \n",
    "   **Logging:** `logs/report.log`  \n",
    "   **Checkpoint:** `checkpoints/report.ok`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5624e955",
   "metadata": {},
   "source": [
    "## B. Dependencies (DAG) — Inline Rendering (No Files Saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa38f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Render a simple DAG inline (no files written)\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.set_axis_off()\n",
    "\n",
    "def _box(ax, x, y, w, h, label):\n",
    "    rect = plt.Rectangle((x, y), w, h, fill=False)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + w/2, y + h/2, label, ha=\"center\", va=\"center\")\n",
    "\n",
    "def _arrow(ax, x1, y1, x2, y2):\n",
    "    ax.annotate(\"\", xy=(x2, y2), xytext=(x1, y1),\n",
    "                arrowprops=dict(arrowstyle=\"->\", lw=1.4))\n",
    "\n",
    "x0, y0, w, h, dx = 0.02, 0.45, 0.15, 0.18, 0.16\n",
    "labels = [\"Ingest\", \"Validate\", \"Clean/Feature\", \"Train\", \"Evaluate\", \"Package\", \"Report\"]\n",
    "xs = [x0 + i*dx for i in range(len(labels))]\n",
    "\n",
    "for xi, lbl in zip(xs, labels):\n",
    "    _box(ax, xi, y0, w, h, lbl)\n",
    "for i in range(len(labels)-1):\n",
    "    _arrow(ax, xs[i]+w, y0+h/2, xs[i+1], y0+h/2)\n",
    "\n",
    "ax.set_xlim(0, 1); ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"DAG rendered inline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7ffcd1",
   "metadata": {},
   "source": [
    "## C. Reliability Patterns — In-Memory Logging, Checkpoints, Idempotency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json, hashlib\n",
    "from typing import Dict, Any, Callable, Tuple\n",
    "\n",
    "# In-memory \"stores\" so nothing is written to disk:\n",
    "MEM_LOGS: Dict[str, list] = {}\n",
    "MEM_CHECKPOINTS: Dict[str, bool] = {}\n",
    "\n",
    "def write_ok(task: str) -> None:\n",
    "    MEM_CHECKPOINTS[task] = True\n",
    "\n",
    "def is_ok(task: str) -> bool:\n",
    "    return MEM_CHECKPOINTS.get(task, False)\n",
    "\n",
    "def mem_log(task: str, message: str) -> None:\n",
    "    MEM_LOGS.setdefault(task, []).append(f\"{time.time():.3f} {message}\")\n",
    "\n",
    "def content_hash(obj: Any) -> str:\n",
    "    payload = json.dumps(obj, sort_keys=True, default=str).encode(\"utf-8\")\n",
    "    return hashlib.sha1(payload).hexdigest()[:8]\n",
    "\n",
    "def run_task(task: str, fn: Callable[[], None], deps: Tuple[str, ...] = ()) -> None:\n",
    "    print(f\"[{task}] start\")\n",
    "    for d in deps:\n",
    "        assert is_ok(d), f\"Upstream checkpoint missing: {d}.ok\"\n",
    "    mem_log(task, \"start\")\n",
    "    fn()\n",
    "    write_ok(task)\n",
    "    mem_log(task, \"done\")\n",
    "    print(f\"[{task}] done -> checkpoint set\")\n",
    "\n",
    "# Demo bodies (replace with real functions)\n",
    "def task_ingest():   time.sleep(0.05)\n",
    "def task_validate(): time.sleep(0.05)\n",
    "def task_clean():    time.sleep(0.05)\n",
    "\n",
    "run_task(\"ingest\", task_ingest)\n",
    "run_task(\"validate\", task_validate, deps=(\"ingest\",))\n",
    "run_task(\"clean\", task_clean, deps=(\"validate\",))\n",
    "\n",
    "print(\"In-memory logs:\", {k: len(v) for k,v in MEM_LOGS.items()})\n",
    "print(\"Checkpoints set:\", [k for k,v in MEM_CHECKPOINTS.items() if v])\n",
    "print(\"Example content hash (params):\", content_hash({\"seed\": 42, \"scale\": True}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e64d5f",
   "metadata": {},
   "source": [
    "## D. Failure Points & Retries\n",
    "\n",
    "- **Schema/CSV drift** → fail fast in **Validate**; retry **0–2** times after upstream fix.  \n",
    "- **Null spikes/parse errors** in **Clean** → quarantine & skip bad rows; retry once.  \n",
    "- **Training instability** → retry with fallback seed; halt with diagnostics if persists.  \n",
    "- **Disk/IO/network** → up to **3** retries with exponential backoff.  \n",
    "- **Threshold breach** in **Evaluate** (e.g., AUC drop/drift) → stop; open ticket; human review before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cdb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time\n",
    "\n",
    "def retry_with_backoff(fn, max_retries: int = 3, base_delay: float = 0.2, jitter: float = 0.1):\n",
    "    \"\"\"\n",
    "    Execute fn() with exponential backoff and jitter.\n",
    "    Returns the return value of fn() or raises the last exception.\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            return fn()\n",
    "        except Exception as e:\n",
    "            if attempt >= max_retries:\n",
    "                print(f\"Retries exhausted at attempt {attempt}.\")\n",
    "                raise\n",
    "            sleep_s = base_delay * (2 ** attempt) + random.uniform(0, jitter)\n",
    "            print(f\"Attempt {attempt} failed: {e}. Backing off {sleep_s:.2f}s\")\n",
    "            time.sleep(sleep_s)\n",
    "            attempt += 1\n",
    "\n",
    "# Demo: retry a flaky function (20% failure rate)\n",
    "def flaky():\n",
    "    if random.random() < 0.2:\n",
    "        raise RuntimeError(\"flaked\")\n",
    "    return \"ok\"\n",
    "\n",
    "print(\"retry_with_backoff result:\", retry_with_backoff(flaky))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73334137",
   "metadata": {},
   "source": [
    "## E. What to Automate Now vs. Manual\n",
    "\n",
    "- **Automate now:** Ingest, Validate, Clean/Feature, Train, Evaluate (deterministic; benefit from re-runs).  \n",
    "- **Manual for now:** Final **Report** polishing; **Package** promotion to prod artifact registry (human gate).  \n",
    "**Rationale:** Prioritize reliability and speed for high-churn steps; keep judgment steps human-reviewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f82c8",
   "metadata": {},
   "source": [
    "## F. Runbook Snippets\n",
    "\n",
    "- **Re-run failed task:** Verify upstream checkpoints exist; clear partial outputs; re-run with same params.  \n",
    "- **Backfill:** Use date-partitioned Ingest; idempotent tasks + content hashes keep outputs consistent.  \n",
    "- **Rollback:** If Evaluate thresholds are violated downstream, block Package and revert to last good artifact hash."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd7ad5",
   "metadata": {},
   "source": [
    "## Deliverables Checklist (Stage 15)\n",
    "\n",
    "- **Pipeline decomposition** (4–8 tasks with boundaries) ✔️  \n",
    "- **DAG** (dependencies) rendered inline ✔️  \n",
    "- **Reliability**: logging, checkpoints, idempotency patterns (in-memory demo) ✔️  \n",
    "- **Failure & retries** policy + backoff utility ✔️  \n",
    "- **Right-sized automation** (now vs manual) ✔️  \n",
    "- **Runbook snippets** ✔️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
