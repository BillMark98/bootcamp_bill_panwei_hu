{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 04: Data Acquisition and Ingestion\n",
        "**Project:** Turtle Trading Strategy Research  \n",
        "**Author:** Panwei Hu  \n",
        "**Date:** 2025-08-17\n",
        "\n",
        "## Objectives\n",
        "- Acquire multi-asset time series data for Turtle Trading backtests\n",
        "- Focus on liquid, diversified universe: Equity ETFs, Bond ETFs, Commodity ETFs, Currency ETFs\n",
        "- Implement robust API ingestion with fallbacks\n",
        "- Validate data quality and save to project data directory\n",
        "- Support both Alpha Vantage API and yfinance as data sources\n",
        "\n",
        "## Data Universe for Turtle Trading\n",
        "The Turtle Trading system requires a diversified set of liquid instruments across multiple asset classes to achieve proper risk diversification and capture trends across different markets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üê¢ Turtle Trading Data Acquisition\n",
            "Project Root: /Users/panweihu/Desktop/Desktop_m1/NYU_mfe/bootcamp/camp4/bootcamp_bill_panwei_hu/turtle_project\n",
            "Data Directory: /Users/panweihu/Desktop/Desktop_m1/NYU_mfe/bootcamp/camp4/bootcamp_bill_panwei_hu/turtle_project/data/raw\n",
            "Alpha Vantage API Key: ‚úÖ Present\n"
          ]
        }
      ],
      "source": [
        "import os, pathlib, datetime as dt\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "from dotenv import load_dotenv\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Set up project paths\n",
        "PROJECT_ROOT = pathlib.Path('..').resolve()\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load environment variables from project root\n",
        "load_dotenv(PROJECT_ROOT / '.env')\n",
        "\n",
        "print(f\"üê¢ Turtle Trading Data Acquisition\")\n",
        "print(f\"Project Root: {PROJECT_ROOT}\")\n",
        "print(f\"Data Directory: {RAW_DIR}\")\n",
        "print(f\"Alpha Vantage API Key: {'‚úÖ Present' if os.getenv('ALPHAVANTAGE_API_KEY') else '‚ùå Missing'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Utility functions loaded\n"
          ]
        }
      ],
      "source": [
        "# Utility functions for data acquisition\n",
        "def ts():\n",
        "    \"\"\"Generate timestamp for unique filenames\"\"\"\n",
        "    return dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "\n",
        "def save_csv(df: pd.DataFrame, prefix: str, **meta):\n",
        "    \"\"\"Save DataFrame with metadata embedded in filename\"\"\"\n",
        "    mid = '_'.join([f\"{k}-{v}\" for k,v in meta.items()])\n",
        "    filename = f\"{prefix}_{mid}_{ts()}.csv\"\n",
        "    path = RAW_DIR / filename\n",
        "    df.to_csv(path, index=False)\n",
        "    print(f\"üíæ Saved: {filename}\")\n",
        "    return path\n",
        "\n",
        "def validate(df: pd.DataFrame, required_cols: list):\n",
        "    \"\"\"Validate DataFrame structure and content\"\"\"\n",
        "    return {\n",
        "        'shape': df.shape,\n",
        "        'missing_cols': [c for c in required_cols if c not in df.columns],\n",
        "        'total_nulls': df.isnull().sum().sum(),\n",
        "        'dtypes': df.dtypes.to_dict()\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Utility functions loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-Asset Universe for Turtle Trading\n",
        "\n",
        "The original Turtle traders focused on futures across multiple asset classes. For this research, we'll use liquid ETFs as proxies to capture the same diversification and trend-following opportunities across:\n",
        "\n",
        "- **Equity Markets**: Broad market exposure across developed and emerging markets\n",
        "- **Fixed Income**: Government and corporate bonds across duration spectrum  \n",
        "- **Commodities**: Precious metals, energy, and agricultural exposure\n",
        "- **Currencies**: Major currency pairs and USD strength/weakness\n",
        "\n",
        "This universe provides the diversification needed for robust trend-following while maintaining high liquidity for realistic backtesting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Turtle Trading Universe: 18 instruments\n",
            "   equity_us: ['SPY', 'QQQ', 'IWM']\n",
            "   equity_intl: ['EFA', 'EEM', 'VEA']\n",
            "   fixed_income: ['TLT', 'IEF', 'LQD', 'HYG']\n",
            "   commodities: ['GLD', 'SLV', 'USO', 'UNG', 'DBA']\n",
            "   currencies: ['FXE', 'FXY', 'UUP']\n",
            "\n",
            "üìä Total symbols to acquire: ['SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'VEA', 'TLT', 'IEF', 'LQD', 'HYG', 'GLD', 'SLV', 'USO', 'UNG', 'DBA', 'FXE', 'FXY', 'UUP']\n"
          ]
        }
      ],
      "source": [
        "# Turtle Trading Asset Universe - Diversified ETF Portfolio\n",
        "TURTLE_UNIVERSE = {\n",
        "    'equity_us': ['SPY', 'QQQ', 'IWM'],  # Large, Tech, Small Cap\n",
        "    'equity_intl': ['EFA', 'EEM', 'VEA'],  # Developed, Emerging, All-World\n",
        "    'fixed_income': ['TLT', 'IEF', 'LQD', 'HYG'],  # Long Treasury, Intermediate, IG Corp, HY\n",
        "    'commodities': ['GLD', 'SLV', 'USO', 'UNG', 'DBA'],  # Gold, Silver, Oil, Gas, Agriculture\n",
        "    'currencies': ['FXE', 'FXY', 'UUP']  # Euro, Yen, USD Bull\n",
        "}\n",
        "\n",
        "# Flatten to single list for data acquisition\n",
        "ALL_SYMBOLS = []\n",
        "for category, symbols in TURTLE_UNIVERSE.items():\n",
        "    ALL_SYMBOLS.extend(symbols)\n",
        "\n",
        "print(f\"üéØ Turtle Trading Universe: {len(ALL_SYMBOLS)} instruments\")\n",
        "for category, symbols in TURTLE_UNIVERSE.items():\n",
        "    print(f\"   {category}: {symbols}\")\n",
        "    \n",
        "print(f\"\\nüìä Total symbols to acquire: {ALL_SYMBOLS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting data acquisition for 18 symbols...\n",
            "Using yfinance (Yahoo Finance)\n",
            "Fetching SPY... ‚úÖ 502 records\n",
            "Fetching QQQ... ‚úÖ 502 records\n",
            "Fetching IWM... ‚úÖ 502 records\n",
            "Fetching EFA... ‚úÖ 502 records\n",
            "Fetching EEM... ‚úÖ 502 records\n",
            "Fetching VEA... ‚úÖ 502 records\n",
            "Fetching TLT... ‚úÖ 502 records\n",
            "Fetching IEF... ‚úÖ 502 records\n",
            "Fetching LQD... ‚úÖ 502 records\n",
            "Fetching HYG... ‚úÖ 502 records\n",
            "Fetching GLD... ‚úÖ 502 records\n",
            "Fetching SLV... ‚úÖ 502 records\n",
            "Fetching USO... ‚úÖ 502 records\n",
            "Fetching UNG... ‚úÖ 502 records\n",
            "Fetching DBA... ‚úÖ 502 records\n",
            "Fetching FXE... ‚úÖ 502 records\n",
            "Fetching FXY... ‚úÖ 502 records\n",
            "Fetching UUP... ‚úÖ 502 records\n",
            "\n",
            "üéâ SUCCESS! Retrieved 9,036 total records for 18 symbols\n",
            "üìä Validation: {'shape': (9036, 4), 'missing_cols': [], 'total_nulls': np.int64(0), 'dtypes': {'date': dtype('<M8[ns]'), 'adj_close': dtype('float64'), 'symbol': dtype('O'), 'asset_category': dtype('O')}}\n",
            "üíæ Saved: turtle_universe_source-yfinance_assets-multi_count-18_20250820-102058.csv\n",
            "\n",
            "üìà Data Summary by Asset Category:\n",
            "                            date            adj_close        \n",
            "                             min        max     count    mean\n",
            "asset_category symbol                                        \n",
            "commodities    DBA    2023-08-21 2025-08-20       502   23.89\n",
            "               GLD    2023-08-21 2025-08-20       502  235.37\n",
            "               SLV    2023-08-21 2025-08-20       502   26.59\n",
            "               UNG    2023-08-21 2025-08-20       502   18.23\n",
            "               USO    2023-08-21 2025-08-20       502   74.15\n",
            "currencies     FXE    2023-08-21 2025-08-20       502   99.08\n",
            "               FXY    2023-08-21 2025-08-20       502   61.82\n",
            "               UUP    2023-08-21 2025-08-20       502   27.47\n",
            "equity_intl    EEM    2023-08-21 2025-08-20       502   41.56\n",
            "               EFA    2023-08-21 2025-08-20       502   76.62\n",
            "               VEA    2023-08-21 2025-08-20       502   48.57\n",
            "equity_us      IWM    2023-08-21 2025-08-20       502  203.62\n",
            "               QQQ    2023-08-21 2025-08-20       502  462.44\n",
            "               SPY    2023-08-21 2025-08-20       502  533.26\n",
            "fixed_income   HYG    2023-08-21 2025-08-20       502   73.53\n",
            "               IEF    2023-08-21 2025-08-20       502   90.86\n",
            "               LQD    2023-08-21 2025-08-20       502  103.11\n",
            "               TLT    2023-08-21 2025-08-20       502   87.58\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Robust Multi-Source Data Acquisition\n",
        "USE_ALPHA = bool(os.getenv('ALPHAVANTAGE_API_KEY'))\n",
        "USE_ALPHA = False\n",
        "all_data = []\n",
        "\n",
        "print(f\"üöÄ Starting data acquisition for {len(ALL_SYMBOLS)} symbols...\")\n",
        "print(f\"Using {'Alpha Vantage API' if USE_ALPHA else 'yfinance (Yahoo Finance)'}\")\n",
        "\n",
        "for symbol in ALL_SYMBOLS:\n",
        "    print(f\"Fetching {symbol}...\", end=' ')\n",
        "    try:\n",
        "        if USE_ALPHA:\n",
        "            # Alpha Vantage API logic (fixed version from homework)\n",
        "            API_KEY = os.getenv('ALPHAVANTAGE_API_KEY')\n",
        "            \n",
        "            url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={symbol}&outputsize=compact&apikey={API_KEY}\"\n",
        "            response = requests.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            \n",
        "            # Handle API responses\n",
        "            if 'Error Message' in data:\n",
        "                print(f\"‚ùå API Error: {data['Error Message']}\")\n",
        "                continue\n",
        "            if 'Note' in data:\n",
        "                print(f\"‚ö†Ô∏è  Rate Limit: {data['Note']}\")\n",
        "                continue\n",
        "            if 'Information' in data:\n",
        "                print(f\"‚ÑπÔ∏è  Info: {data['Information']}\")\n",
        "                continue\n",
        "                \n",
        "            # Find time series data\n",
        "            time_series_key = None\n",
        "            for key in data.keys():\n",
        "                if 'Time Series' in key:\n",
        "                    time_series_key = key\n",
        "                    break\n",
        "                    \n",
        "            if not time_series_key:\n",
        "                print(f\"‚ùå No time series data found\")\n",
        "                continue\n",
        "                \n",
        "            # Process data\n",
        "            df = pd.DataFrame(data[time_series_key]).T.reset_index()\n",
        "            \n",
        "            # Handle different column names\n",
        "            if '5. adjusted close' in df.columns:\n",
        "                df = df.rename(columns={'index': 'date', '5. adjusted close': 'adj_close'})\n",
        "            elif '4. close' in df.columns:\n",
        "                df = df.rename(columns={'index': 'date', '4. close': 'adj_close'})\n",
        "            else:\n",
        "                print(f\"‚ùå Unexpected columns: {list(df.columns)}\")\n",
        "                continue\n",
        "                \n",
        "            df['date'] = pd.to_datetime(df['date'])\n",
        "            df['adj_close'] = pd.to_numeric(df['adj_close'])\n",
        "            df = df[['date', 'adj_close']].copy()\n",
        "            \n",
        "        else:\n",
        "            # yfinance logic (fixed version from homework)\n",
        "            import yfinance as yf\n",
        "            df = yf.download(symbol, period='2y', interval='1d', progress=False, auto_adjust=True)\n",
        "            \n",
        "            if df.empty:\n",
        "                print(\"‚ùå No data\")\n",
        "                continue\n",
        "                \n",
        "            df = df.reset_index()\n",
        "            \n",
        "            # With auto_adjust=True, 'Close' column contains adjusted prices\n",
        "            if 'Close' in df.columns and 'Date' in df.columns:\n",
        "                df = df[['Date', 'Close']].copy()\n",
        "                df.columns = ['date', 'adj_close']\n",
        "            else:\n",
        "                print(f\"‚ùå Unexpected columns: {list(df.columns)}\")\n",
        "                continue\n",
        "        \n",
        "        if df.empty:\n",
        "            print(\"‚ùå Empty data\")\n",
        "            continue\n",
        "            \n",
        "        df['symbol'] = symbol\n",
        "        \n",
        "        # Add asset category for analysis\n",
        "        category = None\n",
        "        for cat, syms in TURTLE_UNIVERSE.items():\n",
        "            if symbol in syms:\n",
        "                category = cat\n",
        "                break\n",
        "        df['asset_category'] = category\n",
        "        \n",
        "        all_data.append(df)\n",
        "        print(f\"‚úÖ {len(df)} records\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        continue\n",
        "\n",
        "# Process and save results\n",
        "if all_data:\n",
        "    df_turtle_data = pd.concat(all_data, ignore_index=True)\n",
        "    print(f\"\\nüéâ SUCCESS! Retrieved {len(df_turtle_data):,} total records for {df_turtle_data['symbol'].nunique()} symbols\")\n",
        "    \n",
        "    # Validation\n",
        "    v_turtle = validate(df_turtle_data, ['date','adj_close','symbol', 'asset_category'])\n",
        "    print(f\"üìä Validation: {v_turtle}\")\n",
        "    \n",
        "    # Save data\n",
        "    df_sorted = df_turtle_data.sort_values(['symbol', 'date']).reset_index(drop=True)\n",
        "    saved_path = save_csv(df_sorted, 'turtle_universe', \n",
        "                         source='alpha' if USE_ALPHA else 'yfinance', \n",
        "                         assets='multi', count=len(ALL_SYMBOLS))\n",
        "    \n",
        "    # Show summary by asset category\n",
        "    print(f\"\\nüìà Data Summary by Asset Category:\")\n",
        "    summary = df_sorted.groupby(['asset_category', 'symbol']).agg({\n",
        "        'date': ['min', 'max'], \n",
        "        'adj_close': ['count', 'mean']\n",
        "    }).round(2)\n",
        "    print(summary)\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No data retrieved! Check your internet connection or API keys.\")\n",
        "    df_turtle_data = pd.DataFrame(columns=['date', 'adj_close', 'symbol', 'asset_category'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mfe_bootcamp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
